{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SEMPIDataLoader import InterPersenSEMPIDataset, DataSetLoader, DataLoader\n",
    "from SEMPIDataLoader import create_dataloaders\n",
    "from SEMPIDataLoader import DATA_PATH\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382 96\n",
      "15256\n",
      "Data loaded successfully!\n",
      "Train size: 12204\n",
      "Val size: 3052\n",
      "Batch 0\n",
      "torch.Size([32, 2, 329, 64])\n",
      "tensor([[6, 1],\n",
      "        [4, 1],\n",
      "        [6, 7],\n",
      "        [6, 7],\n",
      "        [4, 2],\n",
      "        [7, 4],\n",
      "        [2, 5],\n",
      "        [5, 2],\n",
      "        [1, 3],\n",
      "        [5, 2],\n",
      "        [7, 1],\n",
      "        [7, 2],\n",
      "        [8, 4],\n",
      "        [4, 1],\n",
      "        [5, 6],\n",
      "        [5, 7],\n",
      "        [3, 4],\n",
      "        [5, 3],\n",
      "        [5, 3],\n",
      "        [3, 1],\n",
      "        [3, 5],\n",
      "        [2, 8],\n",
      "        [4, 7],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [6, 5],\n",
      "        [5, 2],\n",
      "        [4, 7],\n",
      "        [4, 5],\n",
      "        [1, 5],\n",
      "        [4, 5],\n",
      "        [5, 4]], dtype=torch.int32)\n",
      "tensor([ 3.3333e-02,  1.0000e-01,  1.3333e-01, -1.8333e-01,  8.3333e-02,\n",
      "        -1.6667e-02, -2.7756e-17, -3.3333e-02,  5.0000e-02,  1.6667e-02,\n",
      "         1.0000e-01, -1.6667e-02, -1.0000e-01, -1.3878e-17, -3.1667e-01,\n",
      "        -8.3333e-02,  1.8333e-01, -2.7756e-17, -1.3878e-17, -8.3333e-02,\n",
      "         5.0000e-02,  1.1667e-01, -1.5000e-01,  1.1667e-01,  2.0000e-01,\n",
      "         6.6667e-02,  1.6667e-02, -3.8333e-01, -8.3333e-02, -8.3333e-02,\n",
      "        -1.3333e-01, -3.5000e-01])\n",
      "Batch 1\n",
      "torch.Size([32, 2, 329, 64])\n",
      "tensor([[6, 4],\n",
      "        [1, 6],\n",
      "        [1, 3],\n",
      "        [1, 2],\n",
      "        [3, 6],\n",
      "        [2, 7],\n",
      "        [1, 5],\n",
      "        [3, 1],\n",
      "        [1, 6],\n",
      "        [5, 6],\n",
      "        [2, 1],\n",
      "        [4, 5],\n",
      "        [4, 7],\n",
      "        [6, 4],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [3, 2],\n",
      "        [1, 3],\n",
      "        [5, 6],\n",
      "        [1, 2],\n",
      "        [5, 3],\n",
      "        [2, 6],\n",
      "        [5, 3],\n",
      "        [2, 3],\n",
      "        [6, 5],\n",
      "        [1, 6],\n",
      "        [6, 2],\n",
      "        [5, 4],\n",
      "        [4, 2],\n",
      "        [2, 5],\n",
      "        [6, 4],\n",
      "        [1, 3]], dtype=torch.int32)\n",
      "tensor([-5.0000e-02,  1.6667e-01, -3.3333e-02,  1.0000e-01,  1.5000e-01,\n",
      "        -2.6667e-01,  1.0000e-01,  1.0000e-01, -3.3333e-02,  1.3333e-01,\n",
      "        -1.5000e-01,  8.3333e-02, -1.5000e-01,  1.0000e-01, -2.7756e-17,\n",
      "         1.8333e-01, -1.6667e-02, -8.3333e-02, -2.8333e-01, -2.8333e-01,\n",
      "         5.0000e-02, -6.9389e-18, -3.3333e-02,  2.0000e-01, -1.0000e-01,\n",
      "        -1.3878e-17,  3.3333e-02,  1.0000e-01, -1.6667e-01, -3.0000e-01,\n",
      "         1.1667e-01,  6.6667e-02])\n",
      "Batch 2\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and dataloaders with pickle\n",
    "with open(os.path.join(DATA_PATH, 'dataset.pkl'), 'rb') as f:\n",
    "    dataset: InterPersenSEMPIDataset = pickle.load(f)\n",
    "\n",
    "train_loader, val_loader = create_dataloaders(dataset, batch_size=32)\n",
    "print(len(train_loader), len(val_loader))\n",
    "print(len(dataset))\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Train size: {len(train_loader.dataset)}\")\n",
    "print(f\"Val size: {len(val_loader.dataset)}\")\n",
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    if i == 2:\n",
    "        break\n",
    "    print(data['features'].shape)\n",
    "    print(data['pids'])\n",
    "    print(data['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.3):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Two separate RNNs for the two individuals\n",
    "        self.rnn1 = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='relu', dropout=dropout)\n",
    "        self.rnn2 = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='relu', dropout=dropout)\n",
    "\n",
    "        # Fully connected layer after merging outputs\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the input into two separate individuals\n",
    "        x1, x2 = x[:, 0, :, :], x[:, 1, :, :]  # Each becomes (batch_size, 329, 64)\n",
    "\n",
    "        # Initialize hidden states\n",
    "        h0_1 = torch.zeros(self.num_layers, x1.size(0), self.hidden_size).to(x.device)\n",
    "        h0_2 = torch.zeros(self.num_layers, x2.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Process both individuals separately\n",
    "        out1, _ = self.rnn1(x1, h0_1)\n",
    "        out2, _ = self.rnn2(x2, h0_2)\n",
    "\n",
    "        # Take the output from the last time step of each individual\n",
    "        out1 = out1[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "        out2 = out2[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate both outputs\n",
    "        out = torch.cat((out1, out2), dim=1)  # Shape: (batch_size, hidden_size * 2)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0185\n",
      "Epoch [2/10], Loss: 0.0163\n",
      "Epoch [3/10], Loss: 0.0233\n",
      "Epoch [4/10], Loss: 0.0118\n",
      "Epoch [5/10], Loss: 0.0226\n",
      "Epoch [6/10], Loss: 0.0139\n",
      "Epoch [7/10], Loss: 0.0225\n",
      "Epoch [8/10], Loss: 0.0271\n",
      "Epoch [9/10], Loss: 0.0100\n",
      "Epoch [10/10], Loss: 0.0126\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        features, scores = batch['features'].to(device), batch['score'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), scores)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    actual_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features, scores = batch['features'].to(device), batch['score'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(features).squeeze()\n",
    "\n",
    "            predictions_list.extend(predictions.cpu().numpy())\n",
    "            actual_list.extend(scores.cpu().numpy())\n",
    "\n",
    "    # Convert to NumPy arrays for metric calculations\n",
    "    predictions_list = np.array(predictions_list)\n",
    "    actual_list = np.array(actual_list)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    mse = mean_squared_error(actual_list, predictions_list)\n",
    "    mae = mean_absolute_error(actual_list, predictions_list)\n",
    "    r2 = r2_score(actual_list, predictions_list)\n",
    "\n",
    "    print(f\"Validation Metrics:\\n\"\n",
    "          f\"  - MSE  = {mse:.4f}\\n\"\n",
    "          f\"  - MAE  = {mae:.4f}\\n\"\n",
    "          f\"  - R²   = {r2:.4f}\")\n",
    "\n",
    "    return mse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RNN...\n",
      "Validation Metrics:\n",
      "  - MSE  = 0.0095\n",
      "  - MAE  = 0.0753\n",
      "  - R²   = 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009499510750174522, 0.07533258944749832, 0.5074359178543091)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating RNN...\")\n",
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Two separate LSTMs for each individual\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Fully connected layer after merging outputs\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the input into two separate individuals\n",
    "        x1, x2 = x[:, 0, :, :], x[:, 1, :, :]  # Each becomes (batch_size, 329, 64)\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        h0_1 = torch.zeros(self.num_layers, x1.size(0), self.hidden_size).to(x.device)\n",
    "        c0_1 = torch.zeros(self.num_layers, x1.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        h0_2 = torch.zeros(self.num_layers, x2.size(0), self.hidden_size).to(x.device)\n",
    "        c0_2 = torch.zeros(self.num_layers, x2.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Process both individuals separately\n",
    "        out1, _ = self.lstm1(x1, (h0_1, c0_1))\n",
    "        out2, _ = self.lstm2(x2, (h0_2, c0_2))\n",
    "\n",
    "        # Take the output from the last time step of each individual\n",
    "        out1 = out1[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "        out2 = out2[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate both outputs\n",
    "        out = torch.cat((out1, out2), dim=1)  # Shape: (batch_size, hidden_size * 2)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = 64       # Features per timestep\n",
    "hidden_size = 128     # Hidden units in LSTM\n",
    "num_layers = 2        # LSTM layers\n",
    "output_size = 1       # Predicting a single score\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Define loss function (Huber loss is more robust to outliers)\n",
    "criterion = nn.SmoothL1Loss()  \n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler to reduce LR by half every 3 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0096, LR: 0.001000\n",
      "Epoch [2/10], Loss: 0.0091, LR: 0.001000\n",
      "Epoch [3/10], Loss: 0.0084, LR: 0.000500\n",
      "Epoch [4/10], Loss: 0.0073, LR: 0.000500\n",
      "Epoch [5/10], Loss: 0.0066, LR: 0.000500\n",
      "Epoch [6/10], Loss: 0.0060, LR: 0.000250\n",
      "Epoch [7/10], Loss: 0.0052, LR: 0.000250\n",
      "Epoch [8/10], Loss: 0.0048, LR: 0.000250\n",
      "Epoch [9/10], Loss: 0.0044, LR: 0.000125\n",
      "Epoch [10/10], Loss: 0.0039, LR: 0.000125\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        features, scores = batch['features'].to(device), batch['score'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, scores)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM...\n",
      "Validation Metrics:\n",
      "  - MSE  = 0.0095\n",
      "  - MAE  = 0.0753\n",
      "  - R²   = 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009499510750174522, 0.07533258944749832, 0.5074359178543091)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nEvaluating LSTM...\")\n",
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.3):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Two separate GRUs for each individual\n",
    "        self.gru1 = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.gru2 = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Fully connected layer after merging outputs\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the input into two separate individuals\n",
    "        x1, x2 = x[:, 0, :, :], x[:, 1, :, :]  # Each becomes (batch_size, 329, 64)\n",
    "\n",
    "        # Initialize hidden states\n",
    "        h0_1 = torch.zeros(self.num_layers, x1.size(0), self.hidden_size).to(x.device)\n",
    "        h0_2 = torch.zeros(self.num_layers, x2.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Process both individuals separately\n",
    "        out1, _ = self.gru1(x1, h0_1)\n",
    "        out2, _ = self.gru2(x2, h0_2)\n",
    "\n",
    "        # Take the output from the last time step of each individual\n",
    "        out1 = out1[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "        out2 = out2[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate both outputs\n",
    "        out = torch.cat((out1, out2), dim=1)  # Shape: (batch_size, hidden_size * 2)\n",
    "\n",
    "        # Fully connected layer for final prediction\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0099, LR: 0.001000\n",
      "Epoch [2/10], Loss: 0.0092, LR: 0.001000\n",
      "Epoch [3/10], Loss: 0.0086, LR: 0.000500\n",
      "Epoch [4/10], Loss: 0.0075, LR: 0.000500\n",
      "Epoch [5/10], Loss: 0.0069, LR: 0.000500\n",
      "Epoch [6/10], Loss: 0.0063, LR: 0.000250\n",
      "Epoch [7/10], Loss: 0.0055, LR: 0.000250\n",
      "Epoch [8/10], Loss: 0.0051, LR: 0.000250\n",
      "Epoch [9/10], Loss: 0.0047, LR: 0.000125\n",
      "Epoch [10/10], Loss: 0.0042, LR: 0.000125\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GRU model\n",
    "hidden_size = 128  \n",
    "num_layers = 2  \n",
    "output_size = 1  \n",
    "gru_model = GRUModel(input_size=64, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size).to(device)\n",
    "\n",
    "# Define optimizer, loss, and scheduler\n",
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "criterion = nn.SmoothL1Loss()  # Huber loss\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "# Training loop (same as before)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    gru_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        features, scores = batch['features'].to(device), batch['score'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = gru_model(features).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, scores)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating GRU Model...\n",
      "Validation Metrics:\n",
      "  - MSE  = 0.0101\n",
      "  - MAE  = 0.0776\n",
      "  - R²   = 0.4752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.01012139581143856, 0.07758079469203949, 0.47519028186798096)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Evaluating GRU Model...\")\n",
    "evaluate_model(gru_model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
